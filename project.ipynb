{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "project.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyMmiqt1zwn2MH9so40ZTm2l",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Nadiam75/joint_object_detection_depth_estimation/blob/main/project.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive', force_remount=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "48OnnTXkBhuP",
        "outputId": "837a511f-352d-43b7-ca70-27b52bf6b19d"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# !pip install mat73"
      ],
      "metadata": {
        "id": "T1nylIhDCR7Z"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import scipy.io\n",
        "import cv2\n",
        "import mat73"
      ],
      "metadata": {
        "id": "4Iqms9vnqLqd"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "T8DrWunA_Fpq"
      },
      "outputs": [],
      "source": [
        "dataset_path = 'drive/MyDrive/nyu_depth_v2_labeled.mat'"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data_dict = mat73.loadmat(dataset_path)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vum2_K37CAvo",
        "outputId": "49738c42-ba87-4250-9ecd-64a430258051"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "ERROR:root:ERROR: MATLAB type not supported: containers.Map, (uint32)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# accelData = data_dict ['accelData']\n",
        "depths = data_dict [ 'depths']\n",
        "images = data_dict ['images']\n",
        "# instances = data_dict['instances']\n",
        "# labels = data_dict['labels']\n",
        "# names = data_dict ['names']\n",
        "# namesTolds = data_dict ['namesTolds']\n",
        "# rawDepthFilenames = data_dict [ 'rawDepthFilenames']\n",
        "# rawDepths = data_dict ['rawDepths']\n",
        "# rawRgbFilenames = data_dict['rawRgbFilenames']\n",
        "# sceneTypes = data_dict [ 'sceneTypes']\n",
        "# scenes = data_dict ['scenes']"
      ],
      "metadata": {
        "id": "u07IT5-pHdEf"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# selected_index = 300\n",
        "# plt.figure(figsize=[10, 8])\n",
        "\n",
        "# ax1 = plt.subplot(2, 2, 1)\n",
        "# plt.imshow (instances [:,:,selected_index],  cmap=plt.cm.gist_rainbow)\n",
        "# ax1.set_title('instances')\n",
        "\n",
        "# ax2 = plt.subplot(2, 2, 2)\n",
        "# plt.imshow(labels  [:,:,selected_index] , cmap=plt.cm.gist_rainbow)\n",
        "# ax2.set_title('labels')\n",
        "\n",
        "# ax3 = plt.subplot(2, 2, 3)\n",
        "# plt.imshow(depths  [:,:,selected_index] ,  cmap=plt.cm.gist_rainbow)\n",
        "# ax3.set_title('depths')\n",
        "\n",
        "# ax4 = plt.subplot(2, 2, 4)\n",
        "# plt.imshow(images  [:,:,:,selected_index])\n",
        "# ax4.set_title('images')\n",
        "\n",
        "# plt.show()"
      ],
      "metadata": {
        "id": "JV0tFZcsqwOD"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "images = images.astype('float16')\n",
        "depths = depths.astype('float16')\n",
        "images = np.moveaxis(images, -1, 0)\n",
        "depths = np.moveaxis(depths, -1, 0)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 217
        },
        "id": "HIStgK5cAR2C",
        "outputId": "c575a84d-a57b-4bfd-b1ad-ceb4d6ff6bdf"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-3-bfa697465b96>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mimages\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimages\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'float16'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mdepths\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdepths\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'float16'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mimages\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmoveaxis\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimages\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mdepths\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmoveaxis\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdepths\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'images' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "images.shape"
      ],
      "metadata": {
        "id": "6VKIZ6j22Irt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "depths[:,:,selected_index]"
      ],
      "metadata": {
        "id": "t1ValM8n2_G9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "np.unique(instances[:,:,selected_index])"
      ],
      "metadata": {
        "id": "5PM0UPEl4NFt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "np.unique(labels[:,:,selected_index])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 165
        },
        "id": "CKSUjjwM4RP8",
        "outputId": "f53ad385-a8d8-429d-8ab9-ad1f3ca089b6"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-2-9ea7d03b4bb7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munique\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mselected_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'np' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "instances[:,:,selected_index]"
      ],
      "metadata": {
        "id": "n6a2KE4b8smg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "labels[:,:,selected_index]"
      ],
      "metadata": {
        "id": "8irCLHSa8rwB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers"
      ],
      "metadata": {
        "id": "e4poVHn_4TCI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# data = {\n",
        "#     \"images\": [np.moveaxis(images, -1, 0).astype('float32')],\n",
        "#     \"depths\": [np.moveaxis(depths, -1, 0).astype('float32')],\n",
        "#     \"masks\": [np.moveaxis(labels, -1, 0).astype('float32') ]\n",
        "# # }\n",
        "# # df = pd.DataFrame(data, index = np.arange(1449))\n",
        "\n",
        "# # df = df.sample(frac=1, random_state=42)"
      ],
      "metadata": {
        "id": "3jjz_OjB7A1H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "HEIGHT = 480\n",
        "WIDTH = 640\n",
        "LR = 0.0002\n",
        "EPOCHS = 30\n",
        "BATCH_SIZE = 32"
      ],
      "metadata": {
        "id": "I2Ac7-cLrR3e"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Bf8xZp5g09_D"
      },
      "outputs": [],
      "source": [
        "\n",
        "class DownscaleBlock(layers.Layer):\n",
        "    def __init__(\n",
        "        self, filters, kernel_size=(3, 3), padding=\"same\", strides=1, **kwargs\n",
        "    ):\n",
        "        super().__init__(**kwargs)\n",
        "        self.convA = layers.Conv2D(filters, kernel_size, strides, padding)\n",
        "        self.convB = layers.Conv2D(filters, kernel_size, strides, padding)\n",
        "        self.reluA = layers.LeakyReLU(alpha=0.2)\n",
        "        self.reluB = layers.LeakyReLU(alpha=0.2)\n",
        "        self.bn2a = tf.keras.layers.BatchNormalization()\n",
        "        self.bn2b = tf.keras.layers.BatchNormalization()\n",
        "\n",
        "        self.pool = layers.MaxPool2D((2, 2), (2, 2))\n",
        "\n",
        "    def call(self, input_tensor):\n",
        "        d = self.convA(input_tensor)\n",
        "        x = self.bn2a(d)\n",
        "        x = self.reluA(x)\n",
        "\n",
        "        x = self.convB(x)\n",
        "        x = self.bn2b(x)\n",
        "        x = self.reluB(x)\n",
        "\n",
        "        x += d\n",
        "        p = self.pool(x)\n",
        "        return x, p\n",
        "\n",
        "\n",
        "class UpscaleBlock(layers.Layer):\n",
        "    def __init__(\n",
        "        self, filters, kernel_size=(3, 3), padding=\"same\", strides=1, **kwargs\n",
        "    ):\n",
        "        super().__init__(**kwargs)\n",
        "        self.us = layers.UpSampling2D((2, 2))\n",
        "        self.convA = layers.Conv2D(filters, kernel_size, strides, padding)\n",
        "        self.convB = layers.Conv2D(filters, kernel_size, strides, padding)\n",
        "        self.reluA = layers.LeakyReLU(alpha=0.2)\n",
        "        self.reluB = layers.LeakyReLU(alpha=0.2)\n",
        "        self.bn2a = tf.keras.layers.BatchNormalization()\n",
        "        self.bn2b = tf.keras.layers.BatchNormalization()\n",
        "        self.conc = layers.Concatenate()\n",
        "\n",
        "    def call(self, x, skip):\n",
        "        x = self.us(x)\n",
        "        concat = self.conc([x, skip])\n",
        "        x = self.convA(concat)\n",
        "        x = self.bn2a(x)\n",
        "        x = self.reluA(x)\n",
        "\n",
        "        x = self.convB(x)\n",
        "        x = self.bn2b(x)\n",
        "        x = self.reluB(x)\n",
        "\n",
        "        return x\n",
        "\n",
        "\n",
        "class BottleNeckBlock(layers.Layer):\n",
        "    def __init__(\n",
        "        self, filters, kernel_size=(3, 3), padding=\"same\", strides=1, **kwargs\n",
        "    ):\n",
        "        super().__init__(**kwargs)\n",
        "        self.convA = layers.Conv2D(filters, kernel_size, strides, padding)\n",
        "        self.convB = layers.Conv2D(filters, kernel_size, strides, padding)\n",
        "        self.reluA = layers.LeakyReLU(alpha=0.2)\n",
        "        self.reluB = layers.LeakyReLU(alpha=0.2)\n",
        "\n",
        "    def call(self, x):\n",
        "        x = self.convA(x)\n",
        "        x = self.reluA(x)\n",
        "        x = self.convB(x)\n",
        "        x = self.reluB(x)\n",
        "        return x\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2GbKwubj09_E"
      },
      "outputs": [],
      "source": [
        "\n",
        "class DepthEstimationModel(tf.keras.Model):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.ssim_loss_weight = 0.85\n",
        "        self.l1_loss_weight = 0.1\n",
        "        self.edge_loss_weight = 0.9\n",
        "        self.loss_metric = tf.keras.metrics.Mean(name=\"loss\")\n",
        "        f = [16, 32, 64, 128, 256]\n",
        "        self.downscale_blocks = [  DownscaleBlock(f[0]),  DownscaleBlock(f[1]),DownscaleBlock(f[2]), DownscaleBlock(f[3]), ]\n",
        "        self.bottle_neck_block = BottleNeckBlock(f[4])\n",
        "        self.upscale_blocks = [\n",
        "            UpscaleBlock(f[3]),\n",
        "            UpscaleBlock(f[2]),\n",
        "            UpscaleBlock(f[1]),\n",
        "            UpscaleBlock(f[0]),\n",
        "        ]\n",
        "        self.conv_layer = layers.Conv2D(1, (1, 1), padding=\"same\", activation=\"tanh\" )\n",
        "\n",
        "\n",
        "    def calculate_loss(self, target, pred):\n",
        "        # Edges\n",
        "        dy_true, dx_true = tf.image.image_gradients(target)\n",
        "        dy_pred, dx_pred = tf.image.image_gradients(pred)\n",
        "        weights_x = tf.exp(tf.reduce_mean(tf.abs(dx_true)))\n",
        "        weights_y = tf.exp(tf.reduce_mean(tf.abs(dy_true)))\n",
        "\n",
        "        # Depth smoothness\n",
        "        smoothness_x = dx_pred * weights_x\n",
        "        smoothness_y = dy_pred * weights_y\n",
        "\n",
        "        depth_smoothness_loss = tf.reduce_mean(abs(smoothness_x)) + tf.reduce_mean(\n",
        "            abs(smoothness_y)\n",
        "        )\n",
        "\n",
        "        # Structural similarity (SSIM) index\n",
        "        ssim_loss = tf.reduce_mean(\n",
        "            1\n",
        "            - tf.image.ssim(\n",
        "                target, pred, max_val=WIDTH, filter_size=7, k1=0.01 ** 2, k2=0.03 ** 2\n",
        "            )\n",
        "        )\n",
        "        # Point-wise depth\n",
        "        l1_loss = tf.reduce_mean(tf.abs(target - pred))\n",
        "\n",
        "        loss = (\n",
        "            (self.ssim_loss_weight * ssim_loss)\n",
        "            + (self.l1_loss_weight * l1_loss)\n",
        "            + (self.edge_loss_weight * depth_smoothness_loss)\n",
        "        )\n",
        "\n",
        "        return loss\n",
        "\n",
        "    @property\n",
        "    def metrics(self):\n",
        "        return [self.loss_metric]\n",
        "\n",
        "    # def train_step(self, batch_data):\n",
        "    #     input, target = batch_data\n",
        "    #     with tf.GradientTape() as tape:\n",
        "    #         pred = self(input, training=True)\n",
        "    #         loss = self.calculate_loss(target, pred)\n",
        "\n",
        "    #     gradients = tape.gradient(loss, self.trainable_variables)\n",
        "    #     self.optimizer.apply_gradients(zip(gradients, self.trainable_variables))\n",
        "    #     self.loss_metric.update_state(loss)\n",
        "    #     return {\n",
        "    #         \"loss\": self.loss_metric.result(),\n",
        "    #     }\n",
        "\n",
        "    # def test_step(self, batch_data):\n",
        "    #     input, target = batch_data\n",
        "\n",
        "    #     pred = self(input, training=False)\n",
        "    #     loss = self.calculate_loss(target, pred)\n",
        "\n",
        "    #     self.loss_metric.update_state(loss)\n",
        "    #     return {\n",
        "    #         \"loss\": self.loss_metric.result(),\n",
        "    #     }\n",
        "\n",
        "    def call(self, x):\n",
        "        c1, p1 = self.downscale_blocks[0](x)\n",
        "        c2, p2 = self.downscale_blocks[1](p1)\n",
        "        c3, p3 = self.downscale_blocks[2](p2)\n",
        "        c4, p4 = self.downscale_blocks[3](p3)\n",
        "\n",
        "        bn = self.bottle_neck_block(p4)\n",
        "\n",
        "        u1 = self.upscale_blocks[0](bn, c4)\n",
        "        u2 = self.upscale_blocks[1](u1, c3)\n",
        "        u3 = self.upscale_blocks[2](u2, c2)\n",
        "        u4 = self.upscale_blocks[3](u3, c1)\n",
        "\n",
        "        return self.conv_layer(u4)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "D3LOGCju09_F",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 588
        },
        "outputId": "2696629b-e2cd-4ef4-cc9e-57d426d575ea"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/30\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-25-eaac6d83d5d8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimages\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdepths\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m,\u001b[0m   \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mEPOCHS\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     65\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 67\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     68\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m       \u001b[0;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/func_graph.py\u001b[0m in \u001b[0;36mautograph_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m   1127\u001b[0m           \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint:disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1128\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"ag_error_metadata\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1129\u001b[0;31m               \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mag_error_metadata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1130\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1131\u001b[0m               \u001b[0;32mraise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: in user code:\n\n    File \"/usr/local/lib/python3.7/dist-packages/keras/engine/training.py\", line 878, in train_function  *\n        return step_function(self, iterator)\n    File \"/usr/local/lib/python3.7/dist-packages/keras/engine/training.py\", line 867, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"/usr/local/lib/python3.7/dist-packages/keras/engine/training.py\", line 860, in run_step  **\n        outputs = model.train_step(data)\n    File \"<ipython-input-24-2f816451a1c0>\", line 62, in train_step\n        loss = self.calculate_loss(target, pred)\n    File \"<ipython-input-24-2f816451a1c0>\", line 23, in calculate_loss\n        dy_true, dx_true = tf.image.image_gradients(target)\n\n    ValueError: image_gradients expects a 4D tensor [batch_size, h, w, d], not (None, 480, 640).\n"
          ]
        }
      ],
      "source": [
        "optimizer = tf.keras.optimizers.Adam(\n",
        "    learning_rate=LR,\n",
        "    amsgrad=False,\n",
        ")\n",
        "model = DepthEstimationModel()\n",
        "# Define the loss function\n",
        "cross_entropy = tf.keras.losses.SparseCategoricalCrossentropy(\n",
        "    from_logits=True, reduction=\"none\"\n",
        ")\n",
        "# Compile the model\n",
        "model.compile(optimizer, loss=cross_entropy)\n",
        "\n",
        "\n",
        "model.fit(images[:2], depths[:2] ,   epochs=EPOCHS)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "images[:3].shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ldBvLEQwy3Ji",
        "outputId": "ca057ffa-f8ce-47cd-b76e-d10fe76e8162"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(3, 480, 640, 3)"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "x0U1QQCbCMY1"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}